# -*- coding: utf-8 -*-
"""
Advanced 24/7 Crypto AI Bot - Final Upgraded & Resilient Version
Features: Graceful degradation for missing API keys, DB & Cache fixes,
Multi-chain Analysis, Advanced TA, AI Predictions, Dynamic Risk Management,
Interactive Telegram Bot, Web Dashboard, Enhanced Stability & Modularity.
"""

# ==============================================================================
# 1. IMPORTS
# ==============================================================================
import os
import sys
import time
import asyncio
import logging
import json
import datetime
import re
import io
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional, Tuple

# Third-party imports
import aiohttp
from aiohttp import web
import pandas as pd
import numpy as np
import ccxt.async_support as ccxt
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup, InputFile
from telegram.ext import (
    Application, CommandHandler, ContextTypes, CallbackQueryHandler,
    ConversationHandler, MessageHandler, filters
)
from telegram.constants import ChatAction, ParseMode
from sqlalchemy import (
    create_engine, Column, Integer, String, Float, DateTime,
    Boolean, Text, ForeignKey
)
from sqlalchemy.orm import sessionmaker, relationship, declarative_base
from sqlalchemy.exc import SQLAlchemyError
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from joblib import dump, load
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
import redis
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import tweepy

# ==============================================================================
# 2. CONFIGURATION (SETTINGS)
# ==============================================================================
@dataclass
class Settings:
    # Essential tokens and IDs
    TELEGRAM_BOT_TOKEN: str = os.getenv("TELEGRAM_BOT_TOKEN")
    ADMIN_CHAT_ID: str = os.getenv("ADMIN_CHAT_ID")

    # Database and Cache (Provided by Railway Environment)
    DATABASE_URL: str = os.getenv("DATABASE_URL")
    REDIS_HOST: str = os.getenv('REDIS_HOST')
    REDIS_PORT: int = int(os.getenv('REDIS_PORT', 6379))
    REDIS_PASSWORD: str = os.getenv('REDIS_PASSWORD')

    # API Keys (OPTIONAL - Bot will run without them)
    NEWS_API_KEY: str = os.getenv("NEWS_API_KEY")
    TWITTER_BEARER_TOKEN: str = os.getenv("TWITTER_BEARER_TOKEN")
    ETHERSCAN_API_KEY: str = os.getenv("ETHERSCAN_API_KEY")
    BSCSCAN_API_KEY: str = os.getenv("BSCSCAN_API_KEY")

    # Bot Behavior
    EXCHANGES: List[str] = field(default_factory=lambda: os.getenv("EXCHANGES", "binance,kucoin,bybit").split(","))
    TIMEFRAMES: List[str] = field(default_factory=lambda: os.getenv("TIMEFRAMES", "1h,4h,1d").split(","))
    CACHE_TTL_SECONDS: int = int(os.getenv("CACHE_TTL_SECONDS", "300"))
    REQUEST_TIMEOUT: int = int(os.getenv("REQUEST_TIMEOUT", "20"))

    # Web Dashboard
    ENABLE_WEB_DASHBOARD: bool = os.getenv("ENABLE_WEB_DASHBOARD", "true").lower() == "true"
    WEB_PORT: int = int(os.getenv("WEB_PORT", "8080"))

S = Settings()

# ==============================================================================
# 3. INITIALIZATION (LOGGER, REDIS, DATABASE)
# ==============================================================================
# Logger Setup
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[logging.FileHandler('crypto_bot.log'), logging.StreamHandler(sys.stdout)]
)
logger = logging.getLogger(__name__)

# Redis Client
redis_available = False
redis_client = None
if S.REDIS_HOST and S.REDIS_PASSWORD:
    try:
        redis_client = redis.Redis(
            host=S.REDIS_HOST, port=S.REDIS_PORT, db=0, password=S.REDIS_PASSWORD,
            decode_responses=True, socket_connect_timeout=5
        )
        redis_client.ping()
        redis_available = True
        logger.info("Redis connected successfully.")
    except Exception as e:
        logger.warning(f"Redis connection failed despite credentials being present: {e}")
else:
    logger.warning("Redis credentials not found in environment. Caching will be disabled.")


# Database Setup
Base = declarative_base()

class User(Base):
    __tablename__ = 'users'
    id = Column(Integer, primary_key=True)
    chat_id = Column(Integer, unique=True, nullable=False)
    username = Column(String(50))
    preferences = Column(Text, default='{}')
    risk_level = Column(String(20), default='medium')
    max_leverage = Column(Float, default=5.0)
    balance = Column(Float, default=10000.0)
    created_at = Column(DateTime, default=datetime.datetime.utcnow)
    signals = relationship("Signal", back_populates="user")

class Signal(Base):
    __tablename__ = 'signals'
    id = Column(Integer, primary_key=True)
    user_id = Column(Integer, ForeignKey('users.id'))
    symbol = Column(String(20))
    signal_type = Column(String(10))  # BUY/SELL/HOLD
    confidence = Column(Float)
    price = Column(Float)
    timestamp = Column(DateTime, default=datetime.datetime.utcnow)
    source = Column(String(50))
    timeframe = Column(String(10), default='1h')
    user = relationship("User", back_populates="signals")

if not S.DATABASE_URL:
    logger.critical("FATAL: DATABASE_URL environment variable is not set!")
    sys.exit(1)

try:
    engine = create_engine(S.DATABASE_URL)
    Session = sessionmaker(bind=engine)
    Base.metadata.create_all(engine)
    logger.info("Database connected and tables created.")
except Exception as e:
    logger.critical(f"Database connection failed. Is the driver installed and DATABASE_URL correct? Error: {e}", exc_info=True)
    sys.exit(1)

# ==============================================================================
# 4. HELPER FUNCTIONS
# ==============================================================================
def get_db_session():
    return Session()

def get_or_create_user(session, chat_id, username=None):
    user = session.query(User).filter_by(chat_id=chat_id).first()
    if not user:
        user = User(chat_id=chat_id, username=username)
        session.add(user)
        session.commit()
    elif username and user.username != username:
        user.username = username
        session.commit()
    return user

def cache_set(key: str, value: Any, ttl: int = S.CACHE_TTL_SECONDS):
    if redis_available:
        try:
            redis_client.setex(key, ttl, json.dumps(value, default=str))
        except Exception as e:
            logger.error(f"Redis SET error for key '{key}': {e}")

def cache_get(key: str) -> Optional[Any]:
    if redis_available:
        try:
            cached = redis_client.get(key)
            return json.loads(cached) if cached else None
        except Exception as e:
            logger.error(f"Redis GET error for key '{key}': {e}")
    return None

async def fetch_with_retry(session: aiohttp.ClientSession, url: str, params: dict = None, headers: dict = None, max_retries=3):
    for attempt in range(max_retries):
        try:
            async with session.get(url, params=params, headers=headers, timeout=S.REQUEST_TIMEOUT) as response:
                response.raise_for_status()
                return await response.json()
        except aiohttp.ClientError as e:
            logger.warning(f"Request failed for {url} (attempt {attempt+1}/{max_retries}): {e}")
            if attempt == max_retries - 1:
                raise
            await asyncio.sleep(2 ** attempt)

# ==============================================================================
# 5. CORE ANALYSIS MODULES (TA, Sentiment, AI Prediction)
# ==============================================================================
class AdvancedTechnicalAnalyzer:
    def calculate_rsi(self, prices: pd.Series, period: int = 14) -> pd.Series:
        delta = prices.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
        rs = gain / loss
        return 100 - (100 / (1 + rs))

    def calculate_macd(self, prices: pd.Series, fast: int = 12, slow: int = 26, signal: int = 9) -> Tuple[pd.Series, pd.Series]:
        ema_fast = prices.ewm(span=fast, adjust=False).mean()
        ema_slow = prices.ewm(span=slow, adjust=False).mean()
        macd_line = ema_fast - ema_slow
        signal_line = macd_line.ewm(span=signal, adjust=False).mean()
        return macd_line, signal_line

    def full_analysis(self, df: pd.DataFrame) -> dict:
        if df.empty or len(df) < 200: # Need 200 for SMA
             return {'trend': 'unknown', 'momentum': 'unknown', 'summary': 'Insufficient data'}
        
        close_prices = df['close']
        
        # Trend
        sma_50 = close_prices.rolling(window=50).mean().iloc[-1]
        sma_200 = close_prices.rolling(window=200).mean().iloc[-1]
        trend = 'bullish' if sma_50 > sma_200 else 'bearish' if sma_50 < sma_200 else 'ranging'

        # Momentum
        rsi = self.calculate_rsi(close_prices).iloc[-1]
        macd, signal = self.calculate_macd(close_prices)
        macd_val, signal_val = macd.iloc[-1], signal.iloc[-1]
        
        momentum_score = 0
        if rsi > 70: momentum_score -= 1
        elif rsi < 30: momentum_score += 1
        if macd_val > signal_val: momentum_score += 1
        else: momentum_score -=1

        momentum = 'strong_bullish' if momentum_score > 1 else 'bullish' if momentum_score > 0 else 'strong_bearish' if momentum_score < -1 else 'bearish'
        
        return {
            'trend': trend,
            'momentum': momentum,
            'rsi': rsi,
            'macd_diff': macd_val - signal_val,
            'summary': f"Trend is {trend}, Momentum is {momentum} (RSI: {rsi:.2f})"
        }


class EnhancedSentimentAnalyzer:
    def __init__(self):
        self.vader = SentimentIntensityAnalyzer()
        self.twitter_client = None
        if S.TWITTER_BEARER_TOKEN:
            try:
                self.twitter_client = tweepy.Client(bearer_token=S.TWITTER_BEARER_TOKEN, wait_on_rate_limit=True)
                logger.info("Twitter client initialized successfully.")
            except Exception as e:
                logger.error(f"Failed to initialize Twitter client despite token presence: {e}")
        else:
            logger.warning("TWITTER_BEARER_TOKEN not found. Twitter analysis will be skipped.")

    async def analyze(self, symbol: str) -> dict:
        scores, weights = [], []
        
        if self.twitter_client:
            twitter_score = await self.analyze_twitter(symbol)
            if twitter_score is not None:
                scores.append(twitter_score)
                weights.append(0.6)
        
        if S.NEWS_API_KEY:
            news_score = await self.analyze_news(symbol)
            if news_score is not None:
                scores.append(news_score)
                weights.append(0.4)

        if not scores:
            return {'sentiment': 'neutral', 'score': 0.0, 'summary': 'No data sources available'}

        final_score = np.average(scores, weights=weights if len(weights) == len(scores) and sum(weights)>0 else None)
        sentiment = 'bullish' if final_score > 0.15 else 'bearish' if final_score < -0.15 else 'neutral'
        return {'sentiment': sentiment, 'score': final_score, 'summary': f"Sentiment is {sentiment} (score: {final_score:.2f})"}

    async def analyze_twitter(self, symbol: str) -> Optional[float]:
        try:
            query = f"#{symbol} OR ${symbol} -is:retweet lang:en"
            # Using async wrapper for sync tweepy method
            response = await asyncio.to_thread(self.twitter_client.search_recent_tweets, query=query, max_results=50)
            if not response.data: return 0.0
            scores = [self.vader.polarity_scores(tweet.text)['compound'] for tweet in response.data]
            return np.mean(scores)
        except Exception as e:
            logger.error(f"Twitter sentiment analysis failed for {symbol}: {e}")
            return None

    async def analyze_news(self, symbol: str) -> Optional[float]:
        url = f"https://newsapi.org/v2/everything?q={symbol}&apiKey={S.NEWS_API_KEY}&language=en&pageSize=20"
        try:
            async with aiohttp.ClientSession() as session:
                data = await fetch_with_retry(session, url)
                articles = data.get('articles', [])
                if not articles: return 0.0
                scores = [self.vader.polarity_scores(a['title'] if a['title'] else '')['compound'] for a in articles]
                return np.mean(scores)
        except Exception as e:
            logger.error(f"News sentiment analysis failed for {symbol}: {e}")
            return None

class EnhancedPredictionEngine:
    def __init__(self):
        self.models = {}
        self.scalers = {}
        self.model_path = "./models"
        os.makedirs(self.model_path, exist_ok=True)

    def _prepare_features(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.Series]:
        df['returns'] = df['close'].pct_change()
        df['rsi'] = AdvancedTechnicalAnalyzer().calculate_rsi(df['close'])
        macd, macd_signal = AdvancedTechnicalAnalyzer().calculate_macd(df['close'])
        df['macd_diff'] = macd - macd_signal
        df.dropna(inplace=True)
        
        features = ['returns', 'rsi', 'macd_diff']
        X = df[features]
        y = np.where(df['close'].shift(-1) > df['close'], 1, 0)
        return X, y

    async def train_model(self, symbol: str, df: pd.DataFrame):
        logger.info(f"Training prediction model for {symbol}...")
        try:
            X, y = self._prepare_features(df)
            if len(X) < 50:
                logger.warning(f"Not enough data to train model for {symbol}. Skipping.")
                return

            X_train, _, y_train, _ = train_test_split(X, y, test_size=0.2, shuffle=False)
            
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            
            model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)
            model.fit(X_train_scaled, y_train)

            dump(model, os.path.join(self.model_path, f"{symbol}_model.joblib"))
            dump(scaler, os.path.join(self.model_path, f"{symbol}_scaler.joblib"))
            self.models[symbol] = model
            self.scalers[symbol] = scaler
            logger.info(f"Model for {symbol} trained and saved successfully.")
        except Exception as e:
            logger.error(f"Model training failed for {symbol}: {e}")

    async def predict(self, symbol: str, df: pd.DataFrame) -> dict:
        model_key = f"{symbol}_model.joblib"
        scaler_key = f"{symbol}_scaler.joblib"
        
        if symbol not in self.models:
            try:
                self.models[symbol] = load(os.path.join(self.model_path, model_key))
                self.scalers[symbol] = load(os.path.join(self.model_path, scaler_key))
            except FileNotFoundError:
                await self.train_model(symbol, df.copy())
                if symbol not in self.models:
                    return {'prediction': 'hold', 'confidence': 0.5}
        
        model = self.models.get(symbol)
        scaler = self.scalers.get(symbol)
        if not model or not scaler:
            return {'prediction': 'hold', 'confidence': 0.5}

        X, _ = self._prepare_features(df.copy())
        if X.empty:
            return {'prediction': 'hold', 'confidence': 0.5}
            
        last_features = scaler.transform(X.iloc[-1:].values)
        
        probability = model.predict_proba(last_features)[0][1] # Probability of price increase
        prediction = 'buy' if probability > 0.55 else 'sell' if probability < 0.45 else 'hold'
        confidence = max(probability, 1 - probability)
        
        return {'prediction': prediction, 'confidence': confidence}

# ==============================================================================
# 6. SIGNAL GENERATOR
# ==============================================================================
class SignalGenerator:
    def __init__(self, weights: Dict[str, float] = None):
        self.weights = weights or {
            'ta': 0.4,
            'sentiment': 0.3,
            'prediction': 0.3
        }

    def generate(self, analysis: dict) -> dict:
        scores = {}
        
        ta_summary = analysis['technical_analysis']
        if 'bullish' in ta_summary.get('trend', ''): scores['ta'] = 1.0
        elif 'bearish' in ta_summary.get('trend', ''): scores['ta'] = -1.0
        else: scores['ta'] = 0.0
        if 'bullish' in ta_summary.get('momentum', ''): scores['ta'] = (scores.get('ta', 0) + 0.5)
        elif 'bearish' in ta_summary.get('momentum', ''): scores['ta'] = (scores.get('ta', 0) - 0.5)
        scores['ta'] = np.clip(scores.get('ta', 0), -1, 1)

        sentiment_summary = analysis['sentiment_analysis']
        if sentiment_summary.get('sentiment') == 'bullish': scores['sentiment'] = 1.0
        elif sentiment_summary.get('sentiment') == 'bearish': scores['sentiment'] = -1.0
        else: scores['sentiment'] = 0.0

        prediction_summary = analysis['prediction']
        if prediction_summary.get('prediction') == 'buy': scores['prediction'] = 1.0
        elif prediction_summary.get('prediction') == 'sell': scores['prediction'] = -1.0
        else: scores['prediction'] = 0.0
        
        final_score = (scores.get('ta', 0) * self.weights['ta'] +
                       scores.get('sentiment', 0) * self.weights['sentiment'] +
                       scores.get('prediction', 0) * self.weights['prediction'])
        
        signal = 'BUY' if final_score > 0.35 else 'SELL' if final_score < -0.35 else 'HOLD'
        confidence = abs(final_score)

        return {'signal': signal, 'confidence': confidence, 'score': final_score, 'breakdown': scores}

# ==============================================================================
# 7. MAIN BOT CLASS
# ==============================================================================
class AdvancedCryptoBot:
    def __init__(self):
        # Using a more general exchange, can be configured via env var
        exchange_id = S.EXCHANGES[0] if S.EXCHANGES else 'binance'
        self.exchange = getattr(ccxt, exchange_id)()
        self.ta_analyzer = AdvancedTechnicalAnalyzer()
        self.sentiment_analyzer = EnhancedSentimentAnalyzer()
        self.prediction_engine = EnhancedPredictionEngine()
        self.signal_generator = SignalGenerator()

    async def fetch_ohlcv(self, symbol: str, timeframe: str = '1h', limit: int = 300) -> Optional[pd.DataFrame]:
        cache_key = f"ohlcv_{symbol}_{timeframe}"
        cached_data = cache_get(cache_key)
        if cached_data:
            df = pd.read_json(io.StringIO(cached_data['df']))
            df.index = pd.to_datetime(df.index)
            return df

        try:
            pair = f"{symbol.upper()}/USDT"
            ohlcv = await self.exchange.fetch_ohlcv(pair, timeframe, limit=limit)
            df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
            df.set_index('timestamp', inplace=True)
            cache_set(cache_key, {'df': df.to_json()})
            return df
        except ccxt.BadSymbol:
            logger.warning(f"Symbol {symbol} not found on {self.exchange.id}. Trying next exchange...")
            # Fallback logic can be added here if needed
            return None
        except Exception as e:
            logger.error(f"Failed to fetch OHLCV for {symbol} on {self.exchange.id}: {e}")
            return None
        
    async def close_exchange(self):
        if self.exchange:
            await self.exchange.close()

    async def analyze_symbol(self, symbol: str, user_chat_id: int) -> Optional[dict]:
        symbol = symbol.upper()
        df = await self.fetch_ohlcv(symbol, '1h', 500)
        if df is None or df.empty:
            return None

        tasks = {
            'ta': asyncio.create_task(asyncio.to_thread(self.ta_analyzer.full_analysis, df.copy())),
            'sentiment': asyncio.create_task(self.sentiment_analyzer.analyze(symbol)),
            'prediction': asyncio.create_task(self.prediction_engine.predict(symbol, df.copy()))
        }
        
        results = await asyncio.gather(*tasks.values())
        
        analysis = {
            'symbol': symbol,
            'current_price': df['close'].iloc[-1],
            'technical_analysis': results[0],
            'sentiment_analysis': results[1],
            'prediction': results[2],
        }

        signal_info = self.signal_generator.generate(analysis)
        analysis['signal'] = signal_info

        session = get_db_session()
        try:
            user = get_or_create_user(session, user_chat_id)
            db_signal = Signal(
                user_id=user.id,
                symbol=symbol,
                signal_type=signal_info['signal'],
                confidence=signal_info['confidence'],
                price=analysis['current_price'],
                source='bot_analysis'
            )
            session.add(db_signal)
            session.commit()
        except SQLAlchemyError as e:
            logger.error(f"DB Error saving signal: {e}")
            session.rollback()
        finally:
            session.close()

        return analysis

    async def generate_chart(self, symbol: str, df: pd.DataFrame, analysis: dict) -> InputFile:
        fig = make_subplots(rows=2, cols=1, shared_xaxes=True, vertical_spacing=0.05, row_heights=[0.7, 0.3])
        
        fig.add_trace(go.Candlestick(x=df.index, open=df['open'], high=df['high'], low=df['low'], close=df['close'], name='Price'), row=1, col=1)
        fig.add_trace(go.Bar(x=df.index, y=df['volume'], name='Volume', marker_color='rgba(80,120,220,0.6)'), row=2, col=1)

        signal = analysis['signal']['signal']
        color = 'green' if signal == 'BUY' else 'red' if signal == 'SELL' else 'orange'
        fig.update_layout(
            title=f'<b>${symbol}/USDT Analysis | Signal: <span style="color:{color};">{signal}</span></b>',
            yaxis_title='Price (USDT)',
            xaxis_rangeslider_visible=False,
            template='plotly_dark',
            height=600,
            width=900,
            legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
        )
        
        img_bytes = fig.to_image(format="png")
        return InputFile(io.BytesIO(img_bytes), filename=f"{symbol}_analysis.png")

# ==============================================================================
# 8. TELEGRAM BOT HANDLERS
# ==============================================================================
(START_ROUTES, GETTING_SYMBOL) = range(2)

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    user = update.effective_user
    session = get_db_session()
    try:
        get_or_create_user(session, user.id, user.username)
    finally:
        session.close()

    keyboard = [
        [InlineKeyboardButton("ğŸ” ØªØ­Ù„ÛŒÙ„ ÛŒÚ© Ù†Ù…Ø§Ø¯", callback_data='analyze')],
        [InlineKeyboardButton("âš™ï¸ ØªÙ†Ø¸ÛŒÙ…Ø§Øª (Ø¨Ù‡ Ø²ÙˆØ¯ÛŒ)", callback_data='settings')],
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    await update.message.reply_html(
        rf"Ø³Ù„Ø§Ù… {user.mention_html()}! Ø¨Ù‡ Ø±Ø¨Ø§Øª ØªØ­Ù„ÛŒÙ„Ú¯Ø± Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ú©Ø±ÛŒÙ¾ØªÙˆ Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒØ¯.",
        reply_markup=reply_markup,
    )
    return START_ROUTES

async def ask_for_symbol(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    query = update.callback_query
    await query.answer()
    await query.edit_message_text(text="Ù„Ø·ÙØ§Ù‹ Ù†Ù…Ø§Ø¯ Ø§Ø±Ø² Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø±Ø§ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯ (Ù…Ø«Ø§Ù„: BTC ÛŒØ§ ETH):")
    return GETTING_SYMBOL

async def analyze_and_reply(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    symbol = update.message.text.strip().upper()
    chat_id = update.effective_chat.id
    
    await context.bot.send_chat_action(chat_id=chat_id, action=ChatAction.TYPING)
    msg = await update.message.reply_text(f"Ø¯Ø± Ø­Ø§Ù„ ØªØ­Ù„ÛŒÙ„ {symbol}ØŒ Ù„Ø·ÙØ§Ù‹ Ú©Ù…ÛŒ ØµØ¨Ø± Ú©Ù†ÛŒØ¯...")

    bot_instance: AdvancedCryptoBot = context.application.bot_instance
    analysis = await bot_instance.analyze_symbol(symbol, chat_id)

    if not analysis:
        await msg.edit_text(f"Ù…ØªØ§Ø³ÙØ§Ù†Ù‡ ØªØ­Ù„ÛŒÙ„ {symbol} Ø¨Ø§ Ø®Ø·Ø§ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ø§Ø² ØµØ­Øª Ù†Ø§Ù… Ù†Ù…Ø§Ø¯ Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒØ¯.")
        keyboard = [[InlineKeyboardButton("Ø¨Ø§Ø²Ú¯Ø´Øª Ø¨Ù‡ Ù…Ù†Ùˆ", callback_data='main_menu')]]
        await msg.edit_reply_markup(reply_markup=InlineKeyboardMarkup(keyboard))
        return START_ROUTES

    signal = analysis['signal']
    ta = analysis['technical_analysis']
    senti = analysis['sentiment_analysis']
    pred = analysis['prediction']
    
    signal_emoji = {"BUY": "ğŸŸ¢", "SELL": "ğŸ”´", "HOLD": "ğŸŸ¡"}.get(signal['signal'], "")

    text = (
        f"<b>ğŸ“Š ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ {symbol}/USDT</b>\n"
        f"<i>Ù‚ÛŒÙ…Øª ÙØ¹Ù„ÛŒ: ${analysis['current_price']:.2f}</i>\n\n"
        f"<b>{signal_emoji} Ø³ÛŒÚ¯Ù†Ø§Ù„ Ù†Ù‡Ø§ÛŒÛŒ: {signal['signal']}</b> (Ø§Ø·Ù…ÛŒÙ†Ø§Ù†: {signal['confidence']:.1%})\n\n"
        f"<b> Ø¬Ø²Ø¦ÛŒØ§Øª ØªØ­Ù„ÛŒÙ„: </b>\n"
        f"  - ğŸ“‰ ØªÚ©Ù†ÛŒÚ©Ø§Ù„: Ø±ÙˆÙ†Ø¯ <b>{ta['trend']}</b>ØŒ Ù…ÙˆÙ…Ù†ØªÙˆÙ… <b>{ta['momentum']}</b>\n"
        f"  - ğŸ—£ï¸ Ø§Ø­Ø³Ø§Ø³Ø§Øª: <b>{senti['summary']}</b>\n"
        f"  - ğŸ¤– Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ AI: <b>{pred['prediction']}</b> (Ø§Ø·Ù…ÛŒÙ†Ø§Ù†: {pred['confidence']:.1%})\n"
    )

    df = await bot_instance.fetch_ohlcv(symbol, '1h')
    if df is not None:
        chart = await bot_instance.generate_chart(symbol, df, analysis)
        await context.bot.send_photo(
            chat_id=chat_id,
            photo=chart,
            caption=text,
            parse_mode=ParseMode.HTML,
            reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("ØªØ­Ù„ÛŒÙ„ Ù†Ù…Ø§Ø¯ Ø¯ÛŒÚ¯Ø±", callback_data='analyze')]])
        )
        await msg.delete()
    else: # Fallback if chart generation fails
        await msg.edit_text(text, parse_mode=ParseMode.HTML, reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("ØªØ­Ù„ÛŒÙ„ Ù†Ù…Ø§Ø¯ Ø¯ÛŒÚ¯Ø±", callback_data='analyze')]]))
        
    return START_ROUTES

async def back_to_menu(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    query = update.callback_query
    await query.answer()
    keyboard = [
        [InlineKeyboardButton("ğŸ” ØªØ­Ù„ÛŒÙ„ ÛŒÚ© Ù†Ù…Ø§Ø¯", callback_data='analyze')],
        [InlineKeyboardButton("âš™ï¸ ØªÙ†Ø¸ÛŒÙ…Ø§Øª (Ø¨Ù‡ Ø²ÙˆØ¯ÛŒ)", callback_data='settings')],
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    await query.edit_message_text(
        "Ú†Ù‡ Ú©Ø§Ø±ÛŒ Ø¨Ø±Ø§ÛŒØªØ§Ù† Ø§Ù†Ø¬Ø§Ù… Ø¯Ù‡Ù…ØŸ",
        reply_markup=reply_markup,
    )
    return START_ROUTES

# ==============================================================================
# 9. WEB DASHBOARD (Simplified Health Check)
# ==============================================================================
class WebDashboard:
    def __init__(self):
        self.app = web.Application()
        self.app.router.add_get('/', self.index)

    async def index(self, request):
        return web.Response(text="Crypto AI Bot is running.", content_type="text/html")

    async def run(self):
        runner = web.AppRunner(self.app)
        await runner.setup()
        site = web.TCPSite(runner, '0.0.0.0', S.WEB_PORT)
        await site.start()
        logger.info(f"Web dashboard running on http://0.0.0.0:{S.WEB_PORT}")

# ==============================================================================
# 10. MAIN EXECUTION
# ==============================================================================
async def main():
    if not S.TELEGRAM_BOT_TOKEN:
        logger.critical("FATAL: TELEGRAM_BOT_TOKEN is not set!")
        sys.exit(1)

    bot_instance = AdvancedCryptoBot()
    
    app = Application.builder().token(S.TELEGRAM_BOT_TOKEN).build()
    app.bot_instance = bot_instance

    conv_handler = ConversationHandler(
        entry_points=[CommandHandler('start', start)],
        states={
            START_ROUTES: [
                CallbackQueryHandler(ask_for_symbol, pattern='^analyze$'),
                CallbackQueryHandler(back_to_menu, pattern='^main_menu$'),
            ],
            GETTING_SYMBOL: [
                MessageHandler(filters.TEXT & ~filters.COMMAND, analyze_and_reply)
            ],
        },
        fallbacks=[CommandHandler('start', start)],
        allow_reentry=True
    )
    app.add_handler(conv_handler)

    if S.ENABLE_WEB_DASHBOARD:
        dashboard = WebDashboard()
        asyncio.create_task(dashboard.run())
        
    try:
        logger.info("Bot is starting to poll...")
        await app.initialize()
        await app.start()
        await app.updater.start_polling()
        await asyncio.Event().wait() # Keep it running
    finally:
        await bot_instance.close_exchange()
        await app.updater.stop()
        await app.stop()


if __name__ == '__main__':
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.info("Bot stopped manually.")
    except Exception as e:
        logger.critical(f"Bot failed to start: {e}", exc_info=True)